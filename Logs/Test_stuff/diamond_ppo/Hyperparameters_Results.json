{"n_node": 5, "n_agent": 1, "time_steps": 200000, "reward_for_invalid_action": -200.0, "reward_for_goal": 0, "factor_expensive_edge": 1.0, "prop_stoch": 0.4, "k_edges": null, "grid_size": null, "random_seed_for_training": 30, "random_seed_for_inference": 40, "discount_factor": 1.0, "anneal_lr": false, "learning_rate": 0.00025, "num_update_epochs": 4, "network_type": "FC", "network_activation": "tanh", "log_directory": "diamond_ppo", "hand_crafted_graph": "diamond", "num_steps_before_update": 200, "gae_lambda": 0.95, "clip_eps": 0.2, "vf_coeff": 0.5, "ent_coeff": 0.01, "num_minibatches": 4}
{
    "current_datetime": "2024-11-19 23:22:38"
}
{"Total training time in seconds": 11.869874000549316}

Training results: 
{
    "final_regret": 0.0,
    "final_comparative_ratio": 1.0,
    "avg_reward_last_episode": -2.8,
    "max_reward": -2.0
}
Testing results: 
{
    "average_regret": 0.9552238583564758,
    "average_comparative_ratio": 1.2388060092926025,
    "average_reward": -3.910447835922241
}
Policy: 
[
[0.0, 0.32499998807907104, 0.675000011920929, 0.0],
[0.0, 0.0, 0.0, 1.0],
[0.48148149251937866, 0.0, 0.0, 0.5185185074806213],
[NaN, NaN, NaN, NaN]
]
Network architecture: 
params/Dense_0/bias: (64,)
params/Dense_0/kernel: (60, 64)
params/Dense_1/bias: (64,)
params/Dense_1/kernel: (64, 64)
params/Dense_2/bias: (4,)
params/Dense_2/kernel: (64, 4)
params/Dense_3/bias: (64,)
params/Dense_3/kernel: (60, 64)
params/Dense_4/bias: (64,)
params/Dense_4/kernel: (64, 64)
params/Dense_5/bias: (1,)
params/Dense_5/kernel: (64, 1)

Graph Weights: 
[
[-1, 1, 1, -1],
[1, -1, -1, 3],
[1, -1, -1, 1],
[-1, 3, 1, -1]
]
Blocking Probabilities: 
[
[1.0, 0.0, 0.0, 1.0],
[0.0, 1.0, 1.0, 0.0],
[0.0, 1.0, 1.0, 0.4000000059604645],
[1.0, 0.0, 0.4000000059604645, 1.0]
]