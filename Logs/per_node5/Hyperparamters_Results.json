{"n_node": 5, "n_agent": 1, "time_steps": 1000, "learning_rate": 0.0001, "discount_factor": 1.0, "epsilon_start": 0.8, "epsilon_end": 0.05, "epsilon_exploration_rate": 0.6, "batch_size": 128, "reward_for_invalid_action": -200.0, "reward_for_goal": 0, "factor_expensive_edge": 1.0, "prop_stoch": 0.4, "k_edges": null, "grid_size": 10, "random_seed_for_training": 30, "random_seed_for_inference": 40, "buffer_size": 2000, "target_net_update_freq": 40, "network_type": "CNN", "num_filters": null, "network_size": "[600,300,100,50]", "optimizer": "Adam", "save_model": true, "log_directory": "per_node5", "hand_crafted_graph": "None", "dtype_network_params_f16": false, "no_action_masking": false, "replay_buffer_type": "per", "alpha": 0.6, "beta": 1.0, "double_dqn": false}
{
    "current_datetime": "2024-11-18 16:30:44"
}
{"Total training time in seconds": 30.589694261550903}
{"Last average loss:": 1.2252669304609298}
Training results: 
{
    "final_regret": 1.7999992370605469,
    "final_comparative_ratio": 1.1732434034347534,
    "avg_reward_last_episode": -10.642000198364258,
    "max_reward": -10.390000343322754
}
Testing results: 
{
    "average_regret": 0.2896551489830017,
    "average_comparative_ratio": 1.026944637298584,
    "average_reward": -10.733965873718262
}
Policy: 
[
[NaN, NaN, NaN, NaN, NaN],
[0.0, 0.0, 0.0, 0.0, 1.0],
[0.0, 1.0, 0.0, 0.0, 0.0],
[0.0, 0.8454935550689697, 0.15450644493103027, 0.0, 0.0],
[NaN, NaN, NaN, NaN, NaN]
]
Network architecture: 
Layer: Conv_0, Shape: (1, 1, 3, 20)
Layer: Conv_1, Shape: (2, 2, 20, 40)
Layer: Dense_0, Shape: (1200, 600)
Layer: Dense_1, Shape: (600, 300)
Layer: Dense_2, Shape: (300, 100)
Layer: Dense_3, Shape: (100, 50)
Layer: Dense_4, Shape: (50, 5)
