{"n_node": 5, "n_agent": 1, "time_steps": 1000000, "reward_for_invalid_action": -200.0, "reward_for_goal": 0, "factor_expensive_edge": 1.0, "prop_stoch": 0.4, "k_edges": null, "grid_size": 10, "random_seed_for_training": 30, "random_seed_for_inference": 40, "discount_factor": 1.0, "anneal_lr": false, "learning_rate": 0.00025, "num_update_epochs": 4, "network_type": "FC", "network_activation": "tanh", "log_directory": "test_ppo", "num_steps_before_update": 200, "gae_lambda": 0.95, "clip_eps": 0.3, "vf_coeff": 0.5, "ent_coeff": 0.02, "num_minibatches": 4}
{
    "current_datetime": "2024-11-19 21:00:50"
}
{"Total training time in seconds": 22.191545009613037}

Training results: 
{
    "final_regret": 0.3599996566772461,
    "final_comparative_ratio": 1.0346486568450928,
    "avg_reward_last_episode": -10.75,
    "max_reward": -10.390000343322754
}
Testing results: 
{
    "average_regret": 0.3599996566772461,
    "average_comparative_ratio": 1.0346486568450928,
    "average_reward": -10.75
}
Policy: 
[
[0.0, 0.9800000190734863, 0.0, 0.0, 0.019999999552965164],
[1.0, 0.0, 0.0, 0.0, 0.0],
[NaN, NaN, NaN, NaN, NaN],
[1.0, 0.0, 0.0, 0.0, 0.0],
[NaN, NaN, NaN, NaN, NaN]
]
Network architecture: 
params/Dense_0/bias: (64,)
params/Dense_0/kernel: (90, 64)
params/Dense_1/bias: (64,)
params/Dense_1/kernel: (64, 64)
params/Dense_2/bias: (5,)
params/Dense_2/kernel: (64, 5)
params/Dense_3/bias: (64,)
params/Dense_3/kernel: (90, 64)
params/Dense_4/bias: (64,)
params/Dense_4/kernel: (64, 64)
params/Dense_5/bias: (1,)
params/Dense_5/kernel: (64, 1)
